{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2_NLP.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbecker17/public_work/blob/main/Project_2_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0Kz0Nq4ui4"
      },
      "source": [
        "# Project \\#2 Starter Code\n",
        "Your project should address the categories below. \n",
        "\n",
        "## Problem:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZAVjcWhgBV"
      },
      "source": [
        "# Input Pipeline (sklearn):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "12XGv2fIfTSr",
        "outputId": "6456c749-0de0-4c3e-8e79-e363de9fbaf0"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')\n",
        "data = pandas.read_csv('/content/drive/MyDrive/CS167/datasets/IMDB_dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICUC-PvQ5bP2"
      },
      "source": [
        "## Data Exploration:\n",
        "- Number of samples\n",
        "- Number of classes of the target variable\n",
        "- Number of words per sample\n",
        "- Distribution of sample length\n",
        "- **Something else: get creative :) **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkCmgdf5ZqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5b049227-45c8-4fd7-955c-556ca66e5ac9"
      },
      "source": [
        "## Use cells here to explore the data:\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#number of samples:\n",
        "print(data.count())\n",
        "#total of 50000 data points\n",
        "\n",
        "#number of classes\n",
        "print(set(data[\"sentiment\"]))\n",
        "#options for sentiment are 'negative' or 'positive', so there are 2 options\n",
        "\n",
        "#num words/sample\n",
        "length_sample = []\n",
        "i = 0\n",
        "for row in range(len(data)):\n",
        "  count = 0\n",
        "  curr_review = data.iloc[i,0]\n",
        "  #print(curr_review)\n",
        "  for word in curr_review:\n",
        "    count=count+1\n",
        "  length_sample.append(count)\n",
        "  i = i+1\n",
        "#print(length_sample)\n",
        "print(\"Avg num words per sample: \", sum(length_sample)/len(length_sample))\n",
        "\n",
        "#distribution of sample length\n",
        "plt.hist(length_sample)  \n",
        "plt.show()\n",
        "#np.histogram(length_sample)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review       50000\n",
            "sentiment    50000\n",
            "dtype: int64\n",
            "{'negative', 'positive'}\n",
            "Avg num words per sample:  1309.43102\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F88cmdUcamtK"
      },
      "source": [
        "Above, I looked into the data by looking for the number of samples, which is 50000. I also checked how many classes there were for the reviews to be, as it was possible that there was a classification other than positive or negative. However after looking at the data, the only classes are positive or negative. Moving forward, I found the number of words in every review, however this is also likely including the parts of the reviews that say <\"br\">, therefore this number might be a little large. The average length of all of the samples is 1309.43 words. Looking at the histogram of the sample lengths, there are clearly many more samples on the low end of the range, and very few super wordy reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSuguZ6u5lUl"
      },
      "source": [
        "## Data Preparation:\n",
        "\n",
        "I'm providing you with code that cleans the reviews by making it all lowercase letters and removing stop words. The three cells below do this for you. I still want you to explain what you did with the data here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV4FfvLegTSh",
        "outputId": "b9229a32-1625-4a5e-891a-8c6719dd6bd0"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "#only do next line once\n",
        "nltk.download() #in Corpora tab, download stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "#The NLTK downloader will open, you need to select (d) for Download, and then 'stopwords'then (q) to quit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Unzipping corpora/stopwords.zip.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O053pjFBfu1v"
      },
      "source": [
        "#This is a function that takes in a review, makes sure it is only lower case letters and removes stopwords.\n",
        "#It returns the cleaned review text.\n",
        "def clean_review(review):\n",
        "    #input is a string review\n",
        "    #return is review cleaned of all punctuation, lowercase, and removed nltk stopwords\n",
        "    review = review.replace('<br />', ' ') #I have added this line to get rid of the line break indicator just because it was annoying me.\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\",\" \",review)\n",
        "    lower_case = letters_only.lower()\n",
        "    words = lower_case.split()\n",
        "    for stop_word in stopwords.words(\"english\"):\n",
        "        while stop_word in words:\n",
        "            words.remove(stop_word)\n",
        "    \n",
        "    cleaned = \" \".join(words)\n",
        "    return cleaned"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsA4OodyjLXw"
      },
      "source": [
        "#process the data\n",
        "cleaned_text = []\n",
        "for i in range(5):\n",
        "    cleaned_text.append(clean_review(data[\"review\"][i]))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEjHsILZgk9V"
      },
      "source": [
        "#process the data\n",
        "cleaned_text = []\n",
        "for i in range(len(data)):\n",
        "    cleaned_text.append(clean_review(data[\"review\"][i]))  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMg3P0ZNBvGM",
        "outputId": "4d3d4c28-9bf9-458a-8e63-ef620c36f298"
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one reviewers mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side',\n",
              " 'wonderful little production filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece actors extremely well chosen michael sheen got polari voices pat truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master comedy life realism really comes home little things fantasy guard rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating every surface terribly well done',\n",
              " 'thought wonderful way spend time hot summer weekend sitting air conditioned theater watching light hearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point risk addiction thought proof woody allen still fully control style many us grown love laughed one woody comedies years dare say decade never impressed scarlet johanson managed tone sexy image jumped right average spirited young woman may crown jewel career wittier devil wears prada interesting superman great comedy go see friends',\n",
              " 'basically family little boy jake thinks zombie closet parents fighting time movie slower soap opera suddenly jake decides become rambo kill zombie ok first going make film must decide thriller drama drama movie watchable parents divorcing arguing like real life jake closet totally ruins film expected see boogeyman similar movie instead watched drama meaningless thriller spots well playing parents descent dialogs shots jake ignore',\n",
              " 'petter mattei love time money visually stunning film watch mr mattei offers us vivid portrait human relations movie seems telling us money power success people different situations encounter variation arthur schnitzler play theme director transfers action present time new york different characters meet connect one connected one way another next person one seems know previous point contact stylishly film sophisticated luxurious look taken see people live world live habitat thing one gets souls picture different stages loneliness one inhabits big city exactly best place human relations find sincere fulfillment one discerns case people encounter acting good mr mattei direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier rest talented cast make characters come alive wish mr mattei good luck await anxiously next work']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spDgSTvCg9wk"
      },
      "source": [
        "#establish training and testing dataset\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "    train_test_split(cleaned_text, data['sentiment'], test_size = 0.2, random_state=0) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxpR3Y9IQSXe"
      },
      "source": [
        "###What I did to the data\n",
        "I imported beautiful soup to get a collection of commonly used English stopwords. These words are typically ignored to speed up processing time since they have no connotations. To remove them in the dataset, I replaced them with a space character. To replace the words, however, they all had to be in lowercase so I changed the case of every review. I also removed instances of \"< br />\" as the enter indicator is not helpful for what we are looking for. They were also replaced with space characters. I split the reviews which had the replacements made and rejoined them to get rid of the extra space characters in the reviews. I then trained my model on my freshly cleaned reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-86AHOAkDpge"
      },
      "source": [
        "### Vectorizing the data\n",
        "\n",
        "**CountVectorizer**: Convert a collection of text documents to a matrix of token counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwmex98NDgqJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "#Bag of Words with 5000 most common words\n",
        "vectorizer = CountVectorizer(analyzer='word', max_features = 5000)\n",
        "#find the right 5000 words\n",
        "vectorizer.fit(train_data)\n",
        "\n",
        "#use the vectorizer to transform review strings into word count vectors \n",
        "train_data_vectors = vectorizer.transform(train_data).toarray()\n",
        "test_data_vectors = vectorizer.transform(test_data).toarray()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSQcsLOEAec"
      },
      "source": [
        "## Now use train_data_vectors and test_data_vectors to train/test/tune your sklearn models.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbMdJJgZAzte"
      },
      "source": [
        "###Data Preparation Explaination\n",
        "[1 point]: Explain your data preparation. What did you have to do to get your data in shape for your experiments - word embeddings, stop words, vectorization, tokeniztion, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksNth0KGBSMM"
      },
      "source": [
        "## Data Models:\n",
        "\n",
        "###Metrics \n",
        "[1 point]: What metrics will you use to evaluate your model? Why are these metrics the best for your model? (Hint, this should be more than 'accuracy'). \n",
        "\n",
        "I will be using accuracy, MSE, and MAE.<br>\n",
        "###Model Planning and Execution \n",
        "[1 point]: Identify which learning algorithms you will try and which important parameters you will tune for each one.\n",
        "\n",
        "*    SVC\n",
        "*    SVC with ___ tuned\n",
        "*    PCA\n",
        "*    PCA with ___ tuned\n",
        "*    Perceptron\n",
        "*    Perceptron with ___ tuned\n",
        "*    MLP\n",
        "*    MLP with ___ tuned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnLoUBtlCdPB"
      },
      "source": [
        "###SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QQn-3xBW2oE"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "#load up scikit-learn SVC (Support Vector Classifier)\n",
        "clf = SVC()\n",
        "clf.fit(train_data_vectors,train_sln)\n",
        "predictions = clf.predict(test_data_vectors)\n",
        "\n",
        "#output accuracy\n",
        "print(\"accuracy:\", metrics.accuracy_score(test_sln, predictions))\n",
        "vals = data[\"sentiment\"].unique() ## possible classification values\n",
        "conf_mat = metrics.confusion_matrix(test_sln, predictions, labels=vals)\n",
        "print(pd.DataFrame(conf_mat, index = \"T \" + vals, columns = \"Pred \" + vals))\n",
        "#can do kernal trick to increase dimentionality of data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3BERJblXUJ7"
      },
      "source": [
        "###SVC with tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj79PMeEXTt3"
      },
      "source": [
        "import seaborn as sns\n",
        "clf_tuned = SVC()\n",
        "clf_tuned.fit(train_data_vectors,train_sln)\n",
        "predictions = clf_tuned.predict(test_data_vectors)\n",
        "\n",
        "#output accuracy\n",
        "print(\"accuracy:\", metrics.accuracy_score(test_sln, predictions))\n",
        "\n",
        "\n",
        "pretty = True\n",
        "#This function will print a confusion matrix\n",
        "# It takes the test_slns, the preds, and a boolean variable pretty, which when True will print a prettier confusion matrix and if it's false it will print a standard conf matrix.\n",
        "def print_confusion_matrix(test_sln, preds, pretty):\n",
        "  cf_matrix = confusion_matrix(test_sln, preds,)\n",
        "  if pretty:\n",
        "    sns.heatmap(cf_matrix, annot=True,  xticklabels=['p_positive', 'p_negative'], yticklabels=['t_positive', 't_negative']) #p for predicted, t for true\n",
        "  else:\n",
        "    print(cf_matrix)\n",
        "\n",
        "\n",
        "print_confusion_matrix(test_sln, predictions, True)\n",
        "#can do kernal trick to increase dimentionality of data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e5e6aYpCghM"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9MsYgzqXGDe",
        "outputId": "277b3f4c-1442-4045-9668-4173230a522b"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "extractor = PCA(n_components=2, whiten=True)\n",
        "extractor.fit(train_data_vectors)\n",
        "\n",
        "print('this is the variance/importance of each component')\n",
        "print(extractor.explained_variance_ratio_)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the variance/importance of each component\n",
            "[0.05290782 0.04107314]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzr3GhqTXyXq"
      },
      "source": [
        "###PCA with tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMdkiiF7X0uj",
        "outputId": "cc709e82-013d-4a9b-ba67-a9bfafdfb245"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "extractor = PCA(n_components=7, whiten=True)\n",
        "extractor.fit(train_data_vectors)\n",
        "\n",
        "print('this is the variance/importance of each component')\n",
        "print(extractor.explained_variance_ratio_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the variance/importance of each component\n",
            "[0.05290782 0.04107314 0.01700187 0.00932023 0.00778197 0.00684055\n",
            " 0.00613019]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXulYlTMCkUM"
      },
      "source": [
        "###Perceptron "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fbEOt1BXwt6",
        "outputId": "340eec7a-c83d-4ffe-a9e4-334999d8cf62"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import Perceptron\n",
        "perc = Perceptron()\n",
        "perc.fit(train_data_vectors,train_sln)\n",
        "perc_predictions = perc.predict(test_data_vectors)\n",
        "print(\"Sentiment accuracy:\", metrics.accuracy_score(test_sln, perc_predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment accuracy: 0.8528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUq_q7oEX1nK"
      },
      "source": [
        "###Perceptron with tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w79O0O1lX3f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26559c7d-fcc3-4de1-e5d9-be3a2b2ae5cc"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import Perceptron\n",
        "perc = Perceptron(n_iter_no_change = 10, early_stopping=True)\n",
        "perc.fit(train_data_vectors,train_sln)\n",
        "perc_predictions = perc.predict(test_data_vectors)\n",
        "print(\"Sentiment accuracy:\", metrics.accuracy_score(test_sln, perc_predictions))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment accuracy: 0.8451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFvyGujQCq6X"
      },
      "source": [
        "### Multilayer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh1pdKFTPN9q"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "mlp = MLPClassifier(random_state=0,hidden_layer_sizes = (100,))\n",
        "mlp.fit(train_data_vectors,train_sln)\n",
        "predictions = mlp.predict(test_data_vectors)\n",
        "\n",
        "print(\"Accuracy: \", metrics.accuracy_score(test_sln,predictions))\n",
        "\n",
        "#confusion matric\n",
        "import seaborn as sns\n",
        "\n",
        "pretty = True\n",
        "#This function will print a confusion matrix\n",
        "# It takes the test_slns, the preds, and a boolean variable pretty, which when True will print a prettier confusion matrix and if it's false it will print a standard conf matrix.\n",
        "def print_confusion_matrix(test_sln, preds, pretty):\n",
        "  cf_matrix = confusion_matrix(test_sln, preds,)\n",
        "  if pretty:\n",
        "    sns.heatmap(cf_matrix, annot=True,  xticklabels=['p_positive', 'p_negative'], yticklabels=['t_positive', 't_negative']) #p for predicted, t for true\n",
        "  else:\n",
        "    print(cf_matrix)\n",
        "\n",
        "\n",
        "print_confusion_matrix(test_sln, predictions, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIC-0IjYX4pq"
      },
      "source": [
        "###MLP with tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt9wJUFDX6XO"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "mlp = MLPClassifier(random_state=0,hidden_layer_sizes = (100,), max_iter = 600, early_stopping=True)\n",
        "mlp.fit(train_data_vectors,train_sln)\n",
        "predictions = mlp.predict(test_data_vectors)\n",
        "\n",
        "print(\"Accuracy: \", metrics.accuracy_score(test_sln,predictions))\n",
        "\n",
        "#confusion matric\n",
        "import seaborn as sns\n",
        "\n",
        "pretty = True\n",
        "#This function will print a confusion matrix\n",
        "# It takes the test_slns, the preds, and a boolean variable pretty, which when True will print a prettier confusion matrix and if it's false it will print a standard conf matrix.\n",
        "def print_confusion_matrix(test_sln, preds, pretty):\n",
        "  cf_matrix = confusion_matrix(test_sln, preds,)\n",
        "  if pretty:\n",
        "    sns.heatmap(cf_matrix, annot=True,  xticklabels=['p_positive', 'p_negative'], yticklabels=['t_positive', 't_negative']) #p for predicted, t for true\n",
        "  else:\n",
        "    print(cf_matrix)\n",
        "\n",
        "\n",
        "print_confusion_matrix(test_sln, predictions, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbUmUhc4Bwik"
      },
      "source": [
        "##Results\n",
        "[1 point]: \n",
        "\n",
        "After you conduct your learning experiment, summarize the results you got. Include visualizations as appropriate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuuEBpjwCGvt"
      },
      "source": [
        "## Wrap Up\n",
        "###Bumps in the Road \n",
        "[1 point]: What challenges did you encounter? How did you overcome these challenges? Did you have to adapt your strategy to account for these challenges? Why or why not? <br>\n",
        "###Conclusions: \n",
        "What insights/recommendations do you have? What did you find that was interesting? Which model was your best model, which models didn't work well? Why do you think this is? In general, I want a discussion of your experiment, the results, and what they mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh3F6juAFhXK"
      },
      "source": [
        "# Extra Credit"
      ]
    }
  ]
}